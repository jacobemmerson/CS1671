{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, random, string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Part 0: Utility Functions\n",
    "################################################################################\n",
    "\n",
    "COUNTRY_CODES = ['af', 'cn', 'de', 'fi', 'fr', 'in', 'ir', 'pk', 'za']\n",
    "\n",
    "def start_pad(c):\n",
    "    ''' Returns a padding string of length n to append to the front of text\n",
    "        as a pre-processing step to building n-grams '''\n",
    "    return '~' * c\n",
    "\n",
    "def ngrams(c, text):\n",
    "    ''' Returns the ngrams of the text as tuples where the first element is\n",
    "        the length-n context and the second is the character '''\n",
    "    \n",
    "    # sliding window\n",
    "    ng = []\n",
    "    for x in range(len(text)):\n",
    "        char = text[x]\n",
    "        if x < c:\n",
    "            context = start_pad(c - x) + text[:x] # x = 0, 0 chars, x = 1, 1 char, etc\n",
    "        else:\n",
    "            context = text[x-c:x]\n",
    "\n",
    "        ng.append((context, char))\n",
    "    return ng\n",
    "\n",
    "def create_ngram_model(model_class, path, c=2, k=0):\n",
    "    ''' Creates and returns a new n-gram model '''\n",
    "    model = model_class(c, k)\n",
    "    with open(path, encoding='utf-8', errors='ignore') as f:\n",
    "        model.update(f.read())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('~~~', 'a'),\n",
       " ('~~a', 'b'),\n",
       " ('~ab', 'c'),\n",
       " ('abc', 'a'),\n",
       " ('bca', 'b'),\n",
       " ('cab', 'c')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngrams(3, 'abcabc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Part 1: Basic N-Gram Model\n",
    "################################################################################\n",
    "\n",
    "class NgramModel(object):\n",
    "    ''' A basic n-gram model using add-k smoothing '''\n",
    "\n",
    "    def __init__(self, c, k):\n",
    "        self.ngram_max = c\n",
    "        self.smooth_par = k\n",
    "        self.vocab = set()\n",
    "        self.wc = {}\n",
    "\n",
    "    def get_vocab(self):\n",
    "        ''' Returns the set of characters in the vocab '''\n",
    "        return self.vocab\n",
    "\n",
    "    def update(self, text):\n",
    "        ''' Updates the model n-grams based on text '''\n",
    "        unique = set(text)\n",
    "        self.vocab = self.vocab | unique # | = union\n",
    "        wc = self.wc\n",
    "        for g in ngrams(self.ngram_max, text):\n",
    "            if g[0] in wc:\n",
    "                if g[1] in wc[g[0]]:\n",
    "                    wc[g[0]][g[1]] += 1\n",
    "                else:\n",
    "                    wc[g[0]][g[1]] = 1\n",
    "            else:\n",
    "                wc[g[0]] = {}\n",
    "                wc[g[0]][g[1]] = 1\n",
    "        \n",
    "        self.wc = wc\n",
    "\n",
    "    def prob(self, context, char):\n",
    "        ''' Returns the probability of char appearing after context '''\n",
    "        if context not in self.wc: # return 1/len(V) for a novel context\n",
    "            return 1/len(self.vocab)\n",
    "        \n",
    "        k = self.smooth_par\n",
    "        v = len(self.vocab)\n",
    "        p = 0\n",
    "        counts = self.wc[context]\n",
    "        if char not in counts:\n",
    "            c = 0\n",
    "        else:\n",
    "            c = counts[char]\n",
    "            \n",
    "        # p(char | context) = counts(context, char)/counts(context)\n",
    "        p = (c + k) / (sum(counts.values()) + (0 if k == 0 else v))\n",
    "\n",
    "        return p\n",
    "\n",
    "    def random_char(self, context):\n",
    "        ''' Returns a random character based on the given context and the \n",
    "            n-grams learned by this model '''\n",
    "        \n",
    "        r = random.random()\n",
    "        if context not in self.wc:\n",
    "            x = r / (1/len(self.vocab)) # equal chance with no context\n",
    "            x = math.floor(x)\n",
    "            return list(self.vocab)[x]\n",
    "        \n",
    "        counts = self.wc[context]\n",
    "        total =  sum(counts.values())\n",
    "        curr = 0\n",
    "\n",
    "        for k,v in counts.items():\n",
    "            curr += (v / total)\n",
    "            if r <= curr:\n",
    "                return k\n",
    "\n",
    "        return '-'\n",
    "\n",
    "    def random_text(self, length):\n",
    "        ''' Returns text of the specified character length based on the\n",
    "            n-grams learned by this model '''\n",
    "        \n",
    "        c = self.ngram_max\n",
    "        text = \"\"\n",
    "\n",
    "        for i in range(length):\n",
    "            if i >= c:\n",
    "                context = text[(i - c):i]\n",
    "            else:\n",
    "                context = start_pad(c - i) + text[:i]\n",
    "\n",
    "            text += self.random_char(context)\n",
    "\n",
    "        return text\n",
    "\n",
    "    def perplexity(self, text):\n",
    "        ''' Returns the perplexity of text based on the n-grams learned by\n",
    "            this model '''\n",
    "        perp = 0\n",
    "        c = self.ngram_max\n",
    "\n",
    "        for w in range(len(text)): # take the geometric mean of all chars\n",
    "            if w >= c:\n",
    "                context = text[(w - c):w]\n",
    "            else:\n",
    "                context = start_pad(c - w) + text[:w]\n",
    "            char = text[w]\n",
    "            prob = self.prob(context, char)\n",
    "            if not prob: # catch log(0) <- undefined\n",
    "                return (float('inf'))\n",
    "\n",
    "            perp -= math.log(prob) #\n",
    "        \n",
    "        perp = perp / (len(text))\n",
    "        return math.e**(perp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\log\\left(Perplexity(W)\\right) &= \\log\\left[\\left(\\prod_{i = 1}^{N} \\frac{1}{P(w_i \\mid w_1,\\dots,w_{i-1})} \\right)^{1/N}\\right] \\\\\n",
    "                               &= \\frac{1}{N}\\log\\left[\\prod_{i = 1}^{N} \\frac{1}{P(w_i \\mid w_1,\\dots,w_{i-1})}\\right] \\\\\n",
    "                               &= \\frac{1}{N} \\sum_{i = 1}^{N} \\log\\left[\\frac{1}{P(w_i \\mid w_1,\\dots,w_{i-1})}\\right] \\\\\n",
    "                               &= \\frac{1}{N} \\sum_{i = 1}^{N} \\left[\\log\\left(1\\right) - \\log\\left( P(w_i \\mid w_1,\\dots,w_{i-1} ) \\right)\\right] \\\\\n",
    "                               &= \\frac{1}{N} \\sum_{i = 1}^{N} 0 - \\log\\left( P(w_i \\mid w_1,\\dots,w_{i-1} ) \\right)\\\\\n",
    "\\log\\left(Perplexity(W)\\right) &= -\\frac{1}{N} \\sum_{i = 1}^{N} \\log\\left( P(w_i \\mid w_1,\\dots,w_{i-1} ) \\right) \n",
    "\n",
    "\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'b', 'a'}\n",
      "{'b', 'a', 'c', 'd'}\n",
      "1.0\n",
      "0\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "temp = NgramModel(1, 0)\n",
    "temp.update('abab')\n",
    "print(temp.get_vocab())\n",
    "temp.update('abcd')\n",
    "print(temp.get_vocab())\n",
    "\n",
    "print(temp.prob('a','b'))\n",
    "print(temp.prob('~','c'))\n",
    "print(temp.prob('b','c'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'c',\n",
       " 'c',\n",
       " 'a',\n",
       " 'b',\n",
       " 'b',\n",
       " 'b',\n",
       " 'c',\n",
       " 'a',\n",
       " 'a',\n",
       " 'c',\n",
       " 'b',\n",
       " 'c',\n",
       " 'a',\n",
       " 'b',\n",
       " 'b',\n",
       " 'a',\n",
       " 'd',\n",
       " 'd',\n",
       " 'a',\n",
       " 'a',\n",
       " 'b',\n",
       " 'd',\n",
       " 'b',\n",
       " 'a']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = NgramModel(0, 0)\n",
    "temp.update('abab')\n",
    "temp.update('abcd')\n",
    "random.seed(1)\n",
    "[temp.random_char('') for i in range(25)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abcdabcdbabababcdddbabcdb'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = NgramModel(1, 0)\n",
    "m.update('abab')\n",
    "m.update('abcd')\n",
    "random.seed(1)\n",
    "m.random_text(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Firt be don, bequardoseent. Lore himpon his him, Lornextee imparrociss,\n",
      "And lin courepat inche\n",
      "To to er somentrund arthenceight mestatch fich ourd: lothearguand lade this gracteare Dukeetche ill, way clord:\n",
      "POLIA:\n",
      "GRANTONSON:\n",
      "It th bar le joingueelto\n"
     ]
    }
   ],
   "source": [
    "m = create_ngram_model(NgramModel, 'data/shakespeare_input.txt',2)\n",
    "print(m.random_text(250))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Cupill I\n",
      "est-il?\n",
      "\n",
      "Like Henription; the good from honough much bot: whath\n",
      "where dearls to senance do,\n",
      "Come stribestrust dust her ple goes itself me like no:\n",
      "Sol\n",
      "To wer\n",
      "work, I'll comes a vilst Served:\n",
      "O, be arthis.\n",
      "So find with my fore nake; leg\n"
     ]
    }
   ],
   "source": [
    "m = create_ngram_model(NgramModel, 'data/shakespeare_input.txt',3)\n",
    "print(m.random_text(250))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizens:\n",
      "Why, waited.\n",
      "\n",
      "VALENTIO:\n",
      "What you thine have no far and didst to siness Androus as conventions in me: a barbariation, sways\n",
      "Drag pear it, and wealthou die, lord Pompey.\n",
      "\n",
      "MISTRESS FORD:\n",
      "Greath, I darest with his return, seed most the st\n"
     ]
    }
   ],
   "source": [
    "m = create_ngram_model(NgramModel, 'data/shakespeare_input.txt',4)\n",
    "print(m.random_text(250))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Ye're honest;\n",
      "but yet drunk in hand: I am too choleric.\n",
      "\n",
      "ANTIPHOLUS OF EPHESUS:\n",
      "I needs as valiant youth will cut off, and be that, my lord,\n",
      "As if this busy time.\n",
      "\n",
      "CORIOLANUS:\n",
      "Not I, sir; let me ha't: I have deposed.\n",
      "\n",
      "WARWICK:\n",
      "When we \n"
     ]
    }
   ],
   "source": [
    "m = create_ngram_model(NgramModel, 'data/shakespeare_input.txt',7)\n",
    "print(m.random_text(250))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "We'll burn his body in the holy place,\n",
      "And you within the compass of a praemunire,\n",
      "That therefore never flout at me for what you seek so?\n",
      "\n",
      "LADY FAULCONBRIDGE:\n",
      "King Richard thus removed,\n",
      "Leaving no tract behind.\n",
      "\n",
      "Painter:\n",
      "How shall I understand me: over and beside\n",
      "Signior Baptista Minola,\n",
      "As if he were forgot;\n",
      "And on their skins, as on the bark of trees,\n",
      "Have with our niece a dowry large enough:\n",
      "What, are you merry,\n",
      "If worthier friends had not prevented many. Eros, ho!\n",
      "\n",
      "CLEOPATRA:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "m = create_ngram_model(NgramModel, 'data/shakespeare_input.txt',12)\n",
    "print(m.random_text(500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.189207115002721\n",
      "inf\n",
      "1.515716566510398\n"
     ]
    }
   ],
   "source": [
    "temp = NgramModel(1, 0)\n",
    "temp.update('abab')\n",
    "temp.update('abcd')\n",
    "print(temp.perplexity('abcd'))\n",
    "print(temp.perplexity('abca'))\n",
    "print(temp.perplexity('abcda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14285714285714285\n",
      "0.5714285714285714\n",
      "0.4\n",
      "0.25\n"
     ]
    }
   ],
   "source": [
    "m = NgramModel(1, 1)\n",
    "m.update('abab')\n",
    "m.update('abcd')\n",
    "print(m.prob('a', 'a'))\n",
    "print(m.prob('a', 'b'))\n",
    "print(m.prob('c', 'd'))\n",
    "print(m.prob('d', 'a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Part 2: N-Gram Model with Interpolation\n",
    "################################################################################\n",
    "\n",
    "class NgramModelWithInterpolation(NgramModel):\n",
    "    ''' An n-gram model with interpolation '''\n",
    "\n",
    "    def __init__(self, c, k):\n",
    "        self.ngram_max = c\n",
    "        self.smooth_par = k\n",
    "        self.weights = [1/(c+1)] * (c+1)\n",
    "        self.vocab = set()\n",
    "        self.wc = {}\n",
    "\n",
    "    def set_lambdas(self, lambdas):\n",
    "        if len(lambdas) != (self.ngram_max + 1):\n",
    "            print(\"Error: len(lambdas) does not match max ngram\")\n",
    "        s = sum(lambdas)\n",
    "        if s < 1:\n",
    "            print(\"Error: Weights do not add up to 1.\")\n",
    "        elif s > 1:\n",
    "           print(\"sum(lambdas) > 1, normalizing by sum(lambdas)...\\n\")\n",
    "           t = [x / s for x in lambdas]\n",
    "        else:\n",
    "            t = lambdas\n",
    "        self.weights = t\n",
    "        print(f\"lambdas = {t}\")\n",
    "\n",
    "    def get_vocab(self):\n",
    "        return self.vocab\n",
    "\n",
    "    def update(self, text):\n",
    "        unique = set(text)\n",
    "        self.vocab = self.vocab | unique # | = union\n",
    "        wc = self.wc\n",
    "        for c in range(self.ngram_max,-1,-1):\n",
    "            for g in ngrams(c, text):\n",
    "                if g[0] in wc:\n",
    "                    if g[1] in wc[g[0]]:\n",
    "                        wc[g[0]][g[1]] += 1\n",
    "                    else:\n",
    "                        wc[g[0]][g[1]] = 1\n",
    "                else:\n",
    "                    wc[g[0]] = {}\n",
    "                    wc[g[0]][g[1]] = 1\n",
    "            \n",
    "        self.wc = wc\n",
    "\n",
    "    def prob(self, context, char):\n",
    "\n",
    "        p_interp = 0\n",
    "        lambdas = self.weights\n",
    "\n",
    "        for l in range(len(lambdas)):\n",
    "            t_context = context[l:]\n",
    "            prob = super().prob(t_context, char) # use parent prob \n",
    "            p_interp += lambdas[l] * prob\n",
    "\n",
    "        return p_interp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25\n",
      "0.75\n"
     ]
    }
   ],
   "source": [
    "m = NgramModelWithInterpolation(1, 0)\n",
    "m.update('abab')\n",
    "\n",
    "print(m.prob('a', 'a'))\n",
    "print(m.prob('a', 'b'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum(lambdas) > 1, normalizing by sum(lambdas)...\n",
      "\n",
      "lambdas = [0.6, 0.4]\n"
     ]
    }
   ],
   "source": [
    "m.set_lambdas([3,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2\n",
      "0.8\n"
     ]
    }
   ],
   "source": [
    "print(m.prob('a', 'a'))\n",
    "print(m.prob('a', 'b'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4682539682539682\n",
      "0.4349206349206349\n",
      "0.27222222222222225\n",
      "0.3222222222222222\n"
     ]
    }
   ],
   "source": [
    "m = NgramModelWithInterpolation(2, 1)\n",
    "m.update('abab')\n",
    "m.update('abcd')\n",
    "\n",
    "print(m.prob('~a', 'b'))\n",
    "print(m.prob('ba', 'b'))\n",
    "print(m.prob('~c', 'd'))\n",
    "print(m.prob('bc', 'd'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = create_ngram_model(NgramModelWithInterpolation, 'data/shakespeare_input.txt',c = 3, k = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum(lambdas) > 1, normalizing by sum(lambdas)...\n",
      "\n",
      "lambdas = [0.5555555555555556, 0.2777777777777778, 0.1111111111111111, 0.05555555555555555]\n"
     ]
    }
   ],
   "source": [
    "m.set_lambdas([10,5,2,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First\n",
      "Of hear,\n",
      "The every days thermand seartes, her bell enance.--'God good a mould tal an\n",
      "hear thy heir defell:\n",
      "Did laster;\n",
      "And slaiden grience or C's, my\n",
      "Thusbanisted though me, ladly most fox o'erjure! Troy wors one thy corne,\n",
      "Thy lord, stolen, I know ere monter.\n",
      "\n",
      "MON:\n",
      "Truly brow should not.\n",
      "\n",
      "DUKE:\n",
      "That dish flague\n",
      "Our eart it noon then you have he willance the lord: I'll eyes: but of it one; so sworner caresentle,\n",
      "gift out you; sent on outh ear him\n",
      "Widolint unish ence sworst they'r let leave\n"
     ]
    }
   ],
   "source": [
    "print(m.random_text(500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.288839291741622"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.perplexity(m.random_text(500))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
