{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS1671 Assignment 4: Vector Space Models\n",
    "### Jacob Emmerson\n",
    "Due: Novemeber 20th, 2023 @ 11:59pm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This assignment primarily focuses arround the material from chapter 6 in *Speech and Language Processing* (3rd Ed.)\n",
    "\n",
    "**Primary Question:** How good are vector space representations built using Shakespeare data?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Sources*\n",
    "- https://numpy.org/doc/stable/reference/routines.array-creation.html (NumPy Documentation for Array Initialization)\n",
    "- https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html (Compressed Sparse Rows for Memory Optimization during PPMI calculation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hw4_skeleton_jte27 import *\n",
    "from scipy.stats import kendalltau\n",
    "from collections import defaultdict\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formatting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the limited memory on my machine (WSL2, Max 6GB of Memory with 4 Processors), I subset the data. \n",
    "\n",
    "The subset of data will be used for each experiment. This technique works by selecting either the first $N$ documents or randomly sampling $N$ documents from the given document list. To maintain reproducibility, I use the first $N$ documents. Additionally, the vocabulary is subsetted to only the words that occur within the document subset to reduce memory usage when computing PPMI values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "t, dn, v = read_in_shakespeare()\n",
    "tuples, document_names, vocab = subset_data(t, dn, 12, random = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original |V| = 22602\n",
      "Subset |V| = 14592\n",
      "8010 words not included.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Original |V| = {len(v)}\")\n",
    "print(f\"Subset |V| = {len(vocab)}\")\n",
    "print(f\"{len(v) - len(vocab)} words not included.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_to_index = dict(zip(vocab, range(0, len(vocab))))\n",
    "def get_ranks(matrix, words, vocab, vocab_to_index):\n",
    "    rank_df = pd.DataFrame({'rank' : range(1,11)}).set_index('rank')\n",
    "    for word in words:\n",
    "        ranks, scores = rank_words(vocab_to_index[word], matrix)\n",
    "        t10_words = [vocab[r] for r in ranks[:10]]\n",
    "        t10_scores = np.round(scores[:10], 4)\n",
    "\n",
    "        rank_df[word] = tuple(zip(t10_words,t10_scores))\n",
    "    return rank_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following documents are used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Henry IV',\n",
       " 'Alls well that ends well',\n",
       " 'Loves Labours Lost',\n",
       " 'Taming of the Shrew',\n",
       " 'Antony and Cleopatra',\n",
       " 'Coriolanus',\n",
       " 'Hamlet',\n",
       " 'A Midsummer nights dream',\n",
       " 'Merry Wives of Windsor',\n",
       " 'Romeo and Juliet',\n",
       " 'Richard II',\n",
       " 'King John']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Creating Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw Frequency Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing term document matrix...\n"
     ]
    }
   ],
   "source": [
    "print(\"Computing term document matrix...\")\n",
    "td_matrix = create_term_document_matrix(tuples, document_names, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing term context matrix...\n"
     ]
    }
   ],
   "source": [
    "print(\"Computing term context matrix...\")\n",
    "tc_matrix = create_term_context_matrix(tuples, vocab, context_window_size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Can a word co-occur with itself in a Term-Context Matrix? \n",
    "\n",
    "While it is possible to allow a word to co-occur with itself in a term-context matrix, I do not permit this to happen. The goal of a term-context matrix is to represent the relationships between a target word and all other words, so the inclusion of the word's occurence with itself is not necessary.\n",
    "\n",
    "This circumstance changes if the target happens to be within the context window of itself. An instance of this would be a sentence like \"He is ***very*** *very* excited\" where the target word is emphasized. This example is unlikely to occur in one of Shakespeare's plays; however, it demonstrates an occurence in which a target word may occur with itself. With a large context window, we may see words such as \"the\" or to-be verbs occuring with themselves.\n",
    "\n",
    "Additionally, since we are using cosine similarity as our metric of interest for our experiments, we would not want our frequencies for more common words to be inflated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ctcm(line_tuples, vocab, context_window_size=1):\n",
    "    \"\"\"Returns a numpy array containing the term context matrix for the input lines.\n",
    "\n",
    "    Inputs:\n",
    "      line_tuples: A list of tuples, containing the name of the document and\n",
    "      a tokenized line from that document.\n",
    "      vocab: A list of the tokens in the vocabulary\n",
    "\n",
    "    # NOTE: THIS DOCSTRING WAS UPDATED ON JAN 24, 12:39 PM.\n",
    "\n",
    "    Let n = len(vocab).\n",
    "\n",
    "    Returns:\n",
    "      tc_matrix: A nxn numpy array where A_ij contains the frequency with which\n",
    "          word j was found within context_window_size to the left or right of\n",
    "          word i in any sentence in the tuples.\n",
    "    \"\"\"\n",
    "    n = len(vocab)\n",
    "    cws = context_window_size\n",
    "\n",
    "    word_index = dict(zip(vocab, range(len(vocab))))\n",
    "    tc_matrix = np.zeros(shape = (n,n), dtype = np.int32)\n",
    "\n",
    "    for line in line_tuples:\n",
    "        sentence = line[1] # don't care about documents\n",
    "\n",
    "        for i in range(len(sentence)):\n",
    "            target_index = word_index[sentence[i]] # target word (row index)\n",
    "            \n",
    "            L_win = sentence[max(0, i - cws):(i)] # upper is exclusive\n",
    "            if i == len(sentence): # if we are at the end of the sentence, no upper window \n",
    "              #(i + 1) throws an error\n",
    "                U_win = []\n",
    "            else: \n",
    "                U_win = sentence[(i):(i + cws + 1)] \n",
    "\n",
    "            window = L_win + U_win\n",
    "            for word in window: # add the word instances to the tc_matrix\n",
    "                wj = word_index[word] #context index\n",
    "                tc_matrix[target_index,wj] += 1\n",
    "\n",
    "    return tc_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_tc = ctcm(tuples, vocab, context_window_size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*A version of `create_term_context_matrix` with self-inclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Top 10 Similar Words using a Self-Inclusive Term Context Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>juliet</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(pined, 0.5597)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(waken, 0.4198)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(and, 0.2526)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(drinkings, 0.2021)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(metheglins, 0.1999)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(scamble, 0.1999)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(wills, 0.1941)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(bleeding, 0.1933)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(wakes, 0.1871)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(enter, 0.186)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    juliet\n",
       "rank                      \n",
       "1          (pined, 0.5597)\n",
       "2          (waken, 0.4198)\n",
       "3            (and, 0.2526)\n",
       "4      (drinkings, 0.2021)\n",
       "5     (metheglins, 0.1999)\n",
       "6        (scamble, 0.1999)\n",
       "7          (wills, 0.1941)\n",
       "8       (bleeding, 0.1933)\n",
       "9          (wakes, 0.1871)\n",
       "10          (enter, 0.186)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ranks(bad_tc, ['juliet'], vocab, vocab_to_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exclusive Term Context Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>juliet</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(helena, 0.7085)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(therefore, 0.6935)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(nurse, 0.6871)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(demetrius, 0.6843)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(bertram, 0.681)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(costard, 0.6781)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(falstaff, 0.6771)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(caesar, 0.676)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(her, 0.6709)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(others, 0.6697)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   juliet\n",
       "rank                     \n",
       "1        (helena, 0.7085)\n",
       "2     (therefore, 0.6935)\n",
       "3         (nurse, 0.6871)\n",
       "4     (demetrius, 0.6843)\n",
       "5        (bertram, 0.681)\n",
       "6       (costard, 0.6781)\n",
       "7      (falstaff, 0.6771)\n",
       "8         (caesar, 0.676)\n",
       "9           (her, 0.6709)\n",
       "10       (others, 0.6697)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ranks(tc_matrix, ['juliet'], vocab, vocab_to_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From our above ranks using the word 'juliet', we can see that a term-context matrix which allows for words to co-occure with themselves tends to rank irrelvant words much higher. We can see that these words tend to be more common such as \"and\" as well as \"enter\". Additionally, these words tend to have less of an intuitive reasoning for the similarity. \n",
    "\n",
    "With our exclusive term-context matrix, we see words ranked with a higher cosine similarity which additionally make more sense as being related to \"juliet\". Explanations for these ranks will be expanded on in **Model Evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing tf-idf matrix...\n"
     ]
    }
   ],
   "source": [
    "print(\"Computing tf-idf matrix...\")\n",
    "tf_idf_matrix = create_tf_idf_matrix(td_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save memory, I directly calculate the probabilities where possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $N$ denote the total number of counts in a $w \\times c$ term-context matrix \n",
    "\n",
    "\\begin{align*}\n",
    "PMI(w,c) &= \\log_2 \\frac{P(w,c)}{P(w)P(c)} \\\\\n",
    "         &= \\log_2 \\frac{counts(w,c)/N}{(counts(w)/N) \\cdot (counts(c)/N)} \\\\\n",
    "         &= \\log_2 \\frac{counts(w,c)}{(1/N)counts(w)counts(c)} \\\\\n",
    "         &= \\log_2 \\frac{N \\cdot counts(w,c)}{counts(w) counts(c)}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PPMI can now be efficiently calculated using vector arithmetic and numpy's methods for dealing with negative values and $nans$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ppmi matrix...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kibit/anaconda3/lib/python3.11/site-packages/scipy/sparse/_base.py:665: RuntimeWarning: invalid value encountered in divide\n",
      "  return np.true_divide(self.todense(), other)\n",
      "/home/kibit/pitt/CS1671/A4/hw4_skeleton_jte27.py:183: RuntimeWarning: divide by zero encountered in log2\n",
      "  ppmi_mat = np.log2((tcm * total) / (word_counts * context_counts))\n"
     ]
    }
   ],
   "source": [
    "print(\"Computing ppmi matrix...\")\n",
    "ppmi_matrix = create_ppmi_matrix(tc_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ignore the runtime warnings, these are due to log(0) which are handled during the removal of negative PMI values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate each vector space model, I will find the top 10 most similar words to \n",
    "- juliet\n",
    "- romeo\n",
    "- royal\n",
    "- evil\n",
    "- wicked\n",
    "- he"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that these rankings will likely change if the full dataset is used. These were computed using a subset of 12 documents from the 36 document pool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['juliet', 'romeo', 'royal', 'evil', 'wicked', 'he']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `get_ranks` computes the most similar words using the `rank_words` function as outlined in the assignment guidelines and stores them into a dataframe where each column is our choice word and the rows are tuples of the highest ranked word with a cosine similarity score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Term-Document Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The 10 most similar words to \"['juliet', 'romeo', 'royal', 'evil', 'wicked', 'he']\" using cosine-similarity on term-document frequency matrix are:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>juliet</th>\n",
       "      <th>romeo</th>\n",
       "      <th>royal</th>\n",
       "      <th>evil</th>\n",
       "      <th>wicked</th>\n",
       "      <th>he</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(tips, 1.0)</td>\n",
       "      <td>(tips, 1.0)</td>\n",
       "      <td>(sovereign, 0.9676)</td>\n",
       "      <td>(suit, 0.922)</td>\n",
       "      <td>(offence, 0.9118)</td>\n",
       "      <td>(him, 0.9928)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(carelessly, 1.0)</td>\n",
       "      <td>(mercutio, 1.0)</td>\n",
       "      <td>(forego, 0.9416)</td>\n",
       "      <td>(beam, 0.9152)</td>\n",
       "      <td>(question, 0.9032)</td>\n",
       "      <td>(have, 0.9894)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(grindstone, 1.0)</td>\n",
       "      <td>(discern, 1.0)</td>\n",
       "      <td>(boast, 0.9395)</td>\n",
       "      <td>(employment, 0.9058)</td>\n",
       "      <td>(conscience, 0.9003)</td>\n",
       "      <td>(had, 0.9886)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(overwhelming, 1.0)</td>\n",
       "      <td>(benefice, 1.0)</td>\n",
       "      <td>(crown, 0.9385)</td>\n",
       "      <td>(foolery, 0.9014)</td>\n",
       "      <td>(image, 0.8997)</td>\n",
       "      <td>(cannot, 0.9874)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(baleful, 1.0)</td>\n",
       "      <td>(procures, 1.0)</td>\n",
       "      <td>(highness, 0.9354)</td>\n",
       "      <td>(object, 0.887)</td>\n",
       "      <td>(top, 0.8986)</td>\n",
       "      <td>(would, 0.986)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(unplagued, 1.0)</td>\n",
       "      <td>(teat, 1.0)</td>\n",
       "      <td>(burthen, 0.9301)</td>\n",
       "      <td>(easier, 0.8825)</td>\n",
       "      <td>(gifts, 0.8943)</td>\n",
       "      <td>(known, 0.9796)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(deliciousness, 1.0)</td>\n",
       "      <td>(prostrate, 1.0)</td>\n",
       "      <td>(throw, 0.927)</td>\n",
       "      <td>(rags, 0.8825)</td>\n",
       "      <td>(hell, 0.8918)</td>\n",
       "      <td>(them, 0.9791)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(heap, 1.0)</td>\n",
       "      <td>(conjured, 1.0)</td>\n",
       "      <td>(sorrow, 0.9238)</td>\n",
       "      <td>(behaviors, 0.8825)</td>\n",
       "      <td>(distemper, 0.8911)</td>\n",
       "      <td>(they, 0.975)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(waken, 1.0)</td>\n",
       "      <td>(scathe, 1.0)</td>\n",
       "      <td>(kingly, 0.9174)</td>\n",
       "      <td>(german, 0.8825)</td>\n",
       "      <td>(ambition, 0.8858)</td>\n",
       "      <td>(fellow, 0.9729)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(shelves, 1.0)</td>\n",
       "      <td>(direful, 1.0)</td>\n",
       "      <td>(glory, 0.917)</td>\n",
       "      <td>(quoted, 0.8825)</td>\n",
       "      <td>(effect, 0.8813)</td>\n",
       "      <td>(than, 0.9712)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    juliet             romeo                royal  \\\n",
       "rank                                                                \n",
       "1              (tips, 1.0)       (tips, 1.0)  (sovereign, 0.9676)   \n",
       "2        (carelessly, 1.0)   (mercutio, 1.0)     (forego, 0.9416)   \n",
       "3        (grindstone, 1.0)    (discern, 1.0)      (boast, 0.9395)   \n",
       "4      (overwhelming, 1.0)   (benefice, 1.0)      (crown, 0.9385)   \n",
       "5           (baleful, 1.0)   (procures, 1.0)   (highness, 0.9354)   \n",
       "6         (unplagued, 1.0)       (teat, 1.0)    (burthen, 0.9301)   \n",
       "7     (deliciousness, 1.0)  (prostrate, 1.0)       (throw, 0.927)   \n",
       "8              (heap, 1.0)   (conjured, 1.0)     (sorrow, 0.9238)   \n",
       "9             (waken, 1.0)     (scathe, 1.0)     (kingly, 0.9174)   \n",
       "10          (shelves, 1.0)    (direful, 1.0)       (glory, 0.917)   \n",
       "\n",
       "                      evil                wicked                he  \n",
       "rank                                                                \n",
       "1            (suit, 0.922)     (offence, 0.9118)     (him, 0.9928)  \n",
       "2           (beam, 0.9152)    (question, 0.9032)    (have, 0.9894)  \n",
       "3     (employment, 0.9058)  (conscience, 0.9003)     (had, 0.9886)  \n",
       "4        (foolery, 0.9014)       (image, 0.8997)  (cannot, 0.9874)  \n",
       "5          (object, 0.887)         (top, 0.8986)    (would, 0.986)  \n",
       "6         (easier, 0.8825)       (gifts, 0.8943)   (known, 0.9796)  \n",
       "7           (rags, 0.8825)        (hell, 0.8918)    (them, 0.9791)  \n",
       "8      (behaviors, 0.8825)   (distemper, 0.8911)     (they, 0.975)  \n",
       "9         (german, 0.8825)    (ambition, 0.8858)  (fellow, 0.9729)  \n",
       "10        (quoted, 0.8825)      (effect, 0.8813)    (than, 0.9712)  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\n",
    "    '\\nThe 10 most similar words to \"%s\" using cosine-similarity on term-document matrix are:'\n",
    "    % (words)\n",
    ")\n",
    "get_ranks(td_matrix, words, vocab, vocab_to_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: In our term-document matrix, the rows are word vectors of  dimensions. Do you think that’s enough to represent the meaning of words?\n",
    "\n",
    "I do not think that is enough to represent a good approximation of the meaning of words. Clearly document frequency, regardless of the number of documents, would not be able to cover every caveat of the English language, particularly Shakespearean language where words are frequently being made up. However, we can see that for simple words such as \"royal\" that it is able to select generally similar words. In the case of a proper noun such as 'juliet' or 'romeo', 12 documents is not enough to represent similar words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Term-Context Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The 10 most similar words to \"['juliet', 'romeo', 'royal', 'evil', 'wicked', 'he']\" using cosine-similarity on term-context frequency matrix are:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>juliet</th>\n",
       "      <th>romeo</th>\n",
       "      <th>royal</th>\n",
       "      <th>evil</th>\n",
       "      <th>wicked</th>\n",
       "      <th>he</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(helena, 0.7085)</td>\n",
       "      <td>(she, 0.7231)</td>\n",
       "      <td>(presence, 0.7248)</td>\n",
       "      <td>(only, 0.5112)</td>\n",
       "      <td>(most, 0.6687)</td>\n",
       "      <td>(she, 0.9206)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(therefore, 0.6935)</td>\n",
       "      <td>(dead, 0.6864)</td>\n",
       "      <td>(hand, 0.7151)</td>\n",
       "      <td>(this, 0.4996)</td>\n",
       "      <td>(wall, 0.661)</td>\n",
       "      <td>(it, 0.8611)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(nurse, 0.6871)</td>\n",
       "      <td>(there, 0.6861)</td>\n",
       "      <td>(head, 0.6831)</td>\n",
       "      <td>(which, 0.4959)</td>\n",
       "      <td>(great, 0.6495)</td>\n",
       "      <td>(who, 0.7644)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(demetrius, 0.6843)</td>\n",
       "      <td>(here, 0.6851)</td>\n",
       "      <td>(honour, 0.6822)</td>\n",
       "      <td>(t, 0.49)</td>\n",
       "      <td>(such, 0.642)</td>\n",
       "      <td>(there, 0.7499)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(bertram, 0.681)</td>\n",
       "      <td>(he, 0.6815)</td>\n",
       "      <td>(state, 0.6804)</td>\n",
       "      <td>(loves, 0.4854)</td>\n",
       "      <td>(sweet, 0.6391)</td>\n",
       "      <td>(so, 0.7484)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(costard, 0.6781)</td>\n",
       "      <td>(tybalt, 0.6634)</td>\n",
       "      <td>(sight, 0.6795)</td>\n",
       "      <td>(but, 0.4851)</td>\n",
       "      <td>(pit, 0.6332)</td>\n",
       "      <td>(that, 0.7287)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(falstaff, 0.6771)</td>\n",
       "      <td>(caesar, 0.6598)</td>\n",
       "      <td>(blood, 0.6755)</td>\n",
       "      <td>(aught, 0.4834)</td>\n",
       "      <td>(fair, 0.6249)</td>\n",
       "      <td>(dead, 0.7256)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(caesar, 0.676)</td>\n",
       "      <td>(lucentio, 0.6394)</td>\n",
       "      <td>(fair, 0.6754)</td>\n",
       "      <td>(something, 0.4806)</td>\n",
       "      <td>(woodcock, 0.6233)</td>\n",
       "      <td>(this, 0.7239)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(her, 0.6709)</td>\n",
       "      <td>(juliet, 0.6382)</td>\n",
       "      <td>(great, 0.6713)</td>\n",
       "      <td>(himself, 0.4801)</td>\n",
       "      <td>(commoner, 0.6228)</td>\n",
       "      <td>(which, 0.7124)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(others, 0.6697)</td>\n",
       "      <td>(hamlet, 0.6164)</td>\n",
       "      <td>(company, 0.6693)</td>\n",
       "      <td>(has, 0.4794)</td>\n",
       "      <td>(form, 0.6228)</td>\n",
       "      <td>(indeed, 0.7111)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   juliet               romeo               royal  \\\n",
       "rank                                                                \n",
       "1        (helena, 0.7085)       (she, 0.7231)  (presence, 0.7248)   \n",
       "2     (therefore, 0.6935)      (dead, 0.6864)      (hand, 0.7151)   \n",
       "3         (nurse, 0.6871)     (there, 0.6861)      (head, 0.6831)   \n",
       "4     (demetrius, 0.6843)      (here, 0.6851)    (honour, 0.6822)   \n",
       "5        (bertram, 0.681)        (he, 0.6815)     (state, 0.6804)   \n",
       "6       (costard, 0.6781)    (tybalt, 0.6634)     (sight, 0.6795)   \n",
       "7      (falstaff, 0.6771)    (caesar, 0.6598)     (blood, 0.6755)   \n",
       "8         (caesar, 0.676)  (lucentio, 0.6394)      (fair, 0.6754)   \n",
       "9           (her, 0.6709)    (juliet, 0.6382)     (great, 0.6713)   \n",
       "10       (others, 0.6697)    (hamlet, 0.6164)   (company, 0.6693)   \n",
       "\n",
       "                     evil              wicked                he  \n",
       "rank                                                             \n",
       "1          (only, 0.5112)      (most, 0.6687)     (she, 0.9206)  \n",
       "2          (this, 0.4996)       (wall, 0.661)      (it, 0.8611)  \n",
       "3         (which, 0.4959)     (great, 0.6495)     (who, 0.7644)  \n",
       "4               (t, 0.49)       (such, 0.642)   (there, 0.7499)  \n",
       "5         (loves, 0.4854)     (sweet, 0.6391)      (so, 0.7484)  \n",
       "6           (but, 0.4851)       (pit, 0.6332)    (that, 0.7287)  \n",
       "7         (aught, 0.4834)      (fair, 0.6249)    (dead, 0.7256)  \n",
       "8     (something, 0.4806)  (woodcock, 0.6233)    (this, 0.7239)  \n",
       "9       (himself, 0.4801)  (commoner, 0.6228)   (which, 0.7124)  \n",
       "10          (has, 0.4794)      (form, 0.6228)  (indeed, 0.7111)  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\n",
    "    '\\nThe 10 most similar words to \"%s\" using cosine-similarity on term-context matrix are:'\n",
    "    % (words)\n",
    ")\n",
    "get_ranks(tc_matrix, words, vocab, vocab_to_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In regard to the more accurate term-context matrix, we can see that the term-context matrix does slightly better at finding similar words to proper nouns. Juliet's most similar word is compared to helena which is another fictional character involved in a complicated love story. It is slightly surprising Romeo's top word is \"she\"; however, in Shakespeare's play he was quite the romantic poet, so it is unsurprising his name would co-occur with \"she\" somewhat frequently. Looking at the non-proper nouns, the word 'royal' has decently similar words in both representations. In the term-document matrix, words such as 'sovereign', 'crown', and 'highness' are words which I would consider to be very similar to 'royal'. However, these do not appear in the term-context matrix. That being said, the term-context matrix finds other words which are still similar but in a slightly different sense. Royal in the term-context is more similar to words which represent ruling or governing postitions such as \"head\", \"state\", and \"presence\". \n",
    "\n",
    "Both representations seem to struggle with representing \"evil\" where neither seemed to find words which I would truly consider to be similar to one another.\n",
    "\n",
    "Overall, both vector representations have their issues; however, it is difficult to say whether one is objectively better than the other. Perhaps with more documents these would be different; however, depending on the type of similarity a person is looking for, one method of representation may be preferred over the other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To elaborate on the previous question of whether words can self occur, we can get the ranks using the \"bad\" term-context matrix as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>juliet</th>\n",
       "      <th>romeo</th>\n",
       "      <th>royal</th>\n",
       "      <th>evil</th>\n",
       "      <th>wicked</th>\n",
       "      <th>he</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(pined, 0.5597)</td>\n",
       "      <td>(retorts, 0.5655)</td>\n",
       "      <td>(couplement, 0.5771)</td>\n",
       "      <td>(excels, 0.3483)</td>\n",
       "      <td>(converts, 0.3434)</td>\n",
       "      <td>(heareth, 0.8155)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(waken, 0.4198)</td>\n",
       "      <td>(jour, 0.497)</td>\n",
       "      <td>(presences, 0.4883)</td>\n",
       "      <td>(is, 0.2083)</td>\n",
       "      <td>(dissembling, 0.3235)</td>\n",
       "      <td>(capers, 0.7866)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(and, 0.2526)</td>\n",
       "      <td>(hist, 0.4324)</td>\n",
       "      <td>(chasing, 0.4883)</td>\n",
       "      <td>(this, 0.2029)</td>\n",
       "      <td>(commoner, 0.2873)</td>\n",
       "      <td>(numbered, 0.7407)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(drinkings, 0.2021)</td>\n",
       "      <td>(snatching, 0.3885)</td>\n",
       "      <td>(selves, 0.4078)</td>\n",
       "      <td>(he, 0.1994)</td>\n",
       "      <td>(corpulent, 0.2752)</td>\n",
       "      <td>(parallels, 0.7286)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(metheglins, 0.1999)</td>\n",
       "      <td>(lengthens, 0.3729)</td>\n",
       "      <td>(occupation, 0.3987)</td>\n",
       "      <td>(drivelling, 0.1947)</td>\n",
       "      <td>(copatain, 0.2682)</td>\n",
       "      <td>(stirreth, 0.6895)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(scamble, 0.1999)</td>\n",
       "      <td>(exiled, 0.3415)</td>\n",
       "      <td>(trumpeters, 0.3844)</td>\n",
       "      <td>(indited, 0.1947)</td>\n",
       "      <td>(a, 0.2635)</td>\n",
       "      <td>(nill, 0.646)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(wills, 0.1941)</td>\n",
       "      <td>(rosemary, 0.2875)</td>\n",
       "      <td>(fronts, 0.3332)</td>\n",
       "      <td>(trusts, 0.1947)</td>\n",
       "      <td>(o, 0.2614)</td>\n",
       "      <td>(covetous, 0.6291)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(bleeding, 0.1933)</td>\n",
       "      <td>(slew, 0.2864)</td>\n",
       "      <td>(bail, 0.3206)</td>\n",
       "      <td>(default, 0.1947)</td>\n",
       "      <td>(fiend, 0.2573)</td>\n",
       "      <td>(replenished, 0.6291)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(wakes, 0.1871)</td>\n",
       "      <td>(banished, 0.2321)</td>\n",
       "      <td>(empress, 0.247)</td>\n",
       "      <td>(unbuckles, 0.1947)</td>\n",
       "      <td>(charitable, 0.2538)</td>\n",
       "      <td>(tilts, 0.6044)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(enter, 0.186)</td>\n",
       "      <td>(doff, 0.2143)</td>\n",
       "      <td>(lists, 0.2177)</td>\n",
       "      <td>(abhominable, 0.1947)</td>\n",
       "      <td>(combination, 0.2448)</td>\n",
       "      <td>(enjoys, 0.6044)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    juliet                romeo                 royal  \\\n",
       "rank                                                                    \n",
       "1          (pined, 0.5597)    (retorts, 0.5655)  (couplement, 0.5771)   \n",
       "2          (waken, 0.4198)        (jour, 0.497)   (presences, 0.4883)   \n",
       "3            (and, 0.2526)       (hist, 0.4324)     (chasing, 0.4883)   \n",
       "4      (drinkings, 0.2021)  (snatching, 0.3885)      (selves, 0.4078)   \n",
       "5     (metheglins, 0.1999)  (lengthens, 0.3729)  (occupation, 0.3987)   \n",
       "6        (scamble, 0.1999)     (exiled, 0.3415)  (trumpeters, 0.3844)   \n",
       "7          (wills, 0.1941)   (rosemary, 0.2875)      (fronts, 0.3332)   \n",
       "8       (bleeding, 0.1933)       (slew, 0.2864)        (bail, 0.3206)   \n",
       "9          (wakes, 0.1871)   (banished, 0.2321)      (empress, 0.247)   \n",
       "10          (enter, 0.186)       (doff, 0.2143)       (lists, 0.2177)   \n",
       "\n",
       "                       evil                 wicked                     he  \n",
       "rank                                                                       \n",
       "1          (excels, 0.3483)     (converts, 0.3434)      (heareth, 0.8155)  \n",
       "2              (is, 0.2083)  (dissembling, 0.3235)       (capers, 0.7866)  \n",
       "3            (this, 0.2029)     (commoner, 0.2873)     (numbered, 0.7407)  \n",
       "4              (he, 0.1994)    (corpulent, 0.2752)    (parallels, 0.7286)  \n",
       "5      (drivelling, 0.1947)     (copatain, 0.2682)     (stirreth, 0.6895)  \n",
       "6         (indited, 0.1947)            (a, 0.2635)          (nill, 0.646)  \n",
       "7          (trusts, 0.1947)            (o, 0.2614)     (covetous, 0.6291)  \n",
       "8         (default, 0.1947)        (fiend, 0.2573)  (replenished, 0.6291)  \n",
       "9       (unbuckles, 0.1947)   (charitable, 0.2538)        (tilts, 0.6044)  \n",
       "10    (abhominable, 0.1947)  (combination, 0.2448)       (enjoys, 0.6044)  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ranks(bad_tc, words, vocab, vocab_to_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see again that the most similar words do not seem to make much sense. It was best then to use a matrix which does not allow words to occur with themselves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Term Frequency Inverse Document Frequency Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The 10 most similar words to \"['juliet', 'romeo', 'royal', 'evil', 'wicked', 'he']\" using cosine-similarity on term-context frequency matrix are:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>juliet</th>\n",
       "      <th>romeo</th>\n",
       "      <th>royal</th>\n",
       "      <th>evil</th>\n",
       "      <th>wicked</th>\n",
       "      <th>he</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(thwarted, 1.0)</td>\n",
       "      <td>(thwarted, 1.0)</td>\n",
       "      <td>(confound, 0.9622)</td>\n",
       "      <td>(beam, 0.9656)</td>\n",
       "      <td>(owner, 0.9214)</td>\n",
       "      <td>(businesses, 0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(hood, 1.0)</td>\n",
       "      <td>(dedicate, 1.0)</td>\n",
       "      <td>(highness, 0.9533)</td>\n",
       "      <td>(physic, 0.9124)</td>\n",
       "      <td>(damned, 0.9063)</td>\n",
       "      <td>(minute, 0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(tybalt, 1.0)</td>\n",
       "      <td>(sampson, 1.0)</td>\n",
       "      <td>(sovereign, 0.9495)</td>\n",
       "      <td>(shoot, 0.9048)</td>\n",
       "      <td>(hole, 0.9005)</td>\n",
       "      <td>(commission, 0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(valentio, 1.0)</td>\n",
       "      <td>(assailing, 1.0)</td>\n",
       "      <td>(gracious, 0.9445)</td>\n",
       "      <td>(foolery, 0.9016)</td>\n",
       "      <td>(step, 0.8971)</td>\n",
       "      <td>(squadrons, 0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(conjurations, 1.0)</td>\n",
       "      <td>(conspires, 1.0)</td>\n",
       "      <td>(kingly, 0.9423)</td>\n",
       "      <td>(suit, 0.8957)</td>\n",
       "      <td>(everlasting, 0.8969)</td>\n",
       "      <td>(she, 0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(drier, 1.0)</td>\n",
       "      <td>(healthsome, 1.0)</td>\n",
       "      <td>(crown, 0.9376)</td>\n",
       "      <td>(employment, 0.8956)</td>\n",
       "      <td>(start, 0.8822)</td>\n",
       "      <td>(either, 0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(starveth, 1.0)</td>\n",
       "      <td>(wakened, 1.0)</td>\n",
       "      <td>(ends, 0.935)</td>\n",
       "      <td>(meed, 0.894)</td>\n",
       "      <td>(manners, 0.8791)</td>\n",
       "      <td>(environed, 0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(misadventured, 1.0)</td>\n",
       "      <td>(lessen, 1.0)</td>\n",
       "      <td>(majesty, 0.9308)</td>\n",
       "      <td>(object, 0.8784)</td>\n",
       "      <td>(cursed, 0.8766)</td>\n",
       "      <td>(is, 0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(rebeck, 1.0)</td>\n",
       "      <td>(thrills, 1.0)</td>\n",
       "      <td>(superfluous, 0.9228)</td>\n",
       "      <td>(german, 0.8706)</td>\n",
       "      <td>(fee, 0.8763)</td>\n",
       "      <td>(jude, 0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(augmenting, 1.0)</td>\n",
       "      <td>(unseemly, 1.0)</td>\n",
       "      <td>(war, 0.9132)</td>\n",
       "      <td>(quoted, 0.8706)</td>\n",
       "      <td>(laid, 0.8755)</td>\n",
       "      <td>(grace, 0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    juliet              romeo                  royal  \\\n",
       "rank                                                                   \n",
       "1          (thwarted, 1.0)    (thwarted, 1.0)     (confound, 0.9622)   \n",
       "2              (hood, 1.0)    (dedicate, 1.0)     (highness, 0.9533)   \n",
       "3            (tybalt, 1.0)     (sampson, 1.0)    (sovereign, 0.9495)   \n",
       "4          (valentio, 1.0)   (assailing, 1.0)     (gracious, 0.9445)   \n",
       "5      (conjurations, 1.0)   (conspires, 1.0)       (kingly, 0.9423)   \n",
       "6             (drier, 1.0)  (healthsome, 1.0)        (crown, 0.9376)   \n",
       "7          (starveth, 1.0)     (wakened, 1.0)          (ends, 0.935)   \n",
       "8     (misadventured, 1.0)      (lessen, 1.0)      (majesty, 0.9308)   \n",
       "9            (rebeck, 1.0)     (thrills, 1.0)  (superfluous, 0.9228)   \n",
       "10       (augmenting, 1.0)    (unseemly, 1.0)          (war, 0.9132)   \n",
       "\n",
       "                      evil                 wicked               he  \n",
       "rank                                                                \n",
       "1           (beam, 0.9656)        (owner, 0.9214)  (businesses, 0)  \n",
       "2         (physic, 0.9124)       (damned, 0.9063)      (minute, 0)  \n",
       "3          (shoot, 0.9048)         (hole, 0.9005)  (commission, 0)  \n",
       "4        (foolery, 0.9016)         (step, 0.8971)   (squadrons, 0)  \n",
       "5           (suit, 0.8957)  (everlasting, 0.8969)         (she, 0)  \n",
       "6     (employment, 0.8956)        (start, 0.8822)      (either, 0)  \n",
       "7            (meed, 0.894)      (manners, 0.8791)   (environed, 0)  \n",
       "8         (object, 0.8784)       (cursed, 0.8766)          (is, 0)  \n",
       "9         (german, 0.8706)          (fee, 0.8763)        (jude, 0)  \n",
       "10        (quoted, 0.8706)         (laid, 0.8755)       (grace, 0)  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\n",
    "    '\\nThe 10 most similar words to \"%s\" using cosine-similarity on tf-idf matrix are:'\n",
    "    % (words)\n",
    ")\n",
    "get_ranks(tf_idf_matrix, words, vocab, vocab_to_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note, though the cosine similarities may represent 1, this could be due to the rounded representation. The words were sorted prior to rounding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the tf-idf weights, we can see that the term-document matrix manages to find better words for proper nouns, something I previously mentioned that the term-document matrix struggles with. Though the most similar words are imperfect, we can see that for \"tybalt\" was selected as a similar word to \"juliet\". Tybalt was another member of the Capulet family, so it makes sense that he would be selected as a similar proper noun. Under both \"juliet\" and \"romeo\", we see the word \"thwarted\" was selected as the most similar word. This makes sense since both characters went against their parents wishes and thwarting is similar to opposing in terms of meaning. \n",
    "\n",
    "In addition to this, it retains it ability to generalize less specific words such as \"royal\" with some minor improvements in my opinion. In the unweighted matrix, \"forego\" and \"throw\" were selected as similar words to \"royal\" which, in my opinion, were not very similar words to \"royal\"; however, these are no longer selected as similar words. Instead we see terms such as \"war\" and \"majesty\" which make much more sense as being similar to royal.\n",
    "\n",
    "Another thing to note is that no words were considered very similar to \"he\". This makes sense given that \"he\" is a common word and the tf-idf weighting techinque prevents common words from being similar to other words through the addition of the inverse document frequency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positive Pointwise Mutual Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The 10 most similar words to \"['juliet', 'romeo', 'royal', 'evil', 'wicked', 'he']\" using cosine-similarity on term-context frequency matrix are:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>juliet</th>\n",
       "      <th>romeo</th>\n",
       "      <th>royal</th>\n",
       "      <th>evil</th>\n",
       "      <th>wicked</th>\n",
       "      <th>he</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(capulet, 0.1819)</td>\n",
       "      <td>(mercutio, 0.2296)</td>\n",
       "      <td>(encountering, 0.1827)</td>\n",
       "      <td>(discoveries, 0.3079)</td>\n",
       "      <td>(spectacle, 0.2403)</td>\n",
       "      <td>(hath, 0.1525)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(tybalt, 0.1721)</td>\n",
       "      <td>(hist, 0.2165)</td>\n",
       "      <td>(carters, 0.1406)</td>\n",
       "      <td>(ministering, 0.2747)</td>\n",
       "      <td>(bombast, 0.2196)</td>\n",
       "      <td>(that, 0.1416)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(katarina, 0.1595)</td>\n",
       "      <td>(bon, 0.1892)</td>\n",
       "      <td>(dismantled, 0.1226)</td>\n",
       "      <td>(clerks, 0.2669)</td>\n",
       "      <td>(absurd, 0.1914)</td>\n",
       "      <td>(it, 0.1257)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(paris, 0.1534)</td>\n",
       "      <td>(jour, 0.1836)</td>\n",
       "      <td>(peril, 0.1184)</td>\n",
       "      <td>(crawl, 0.2594)</td>\n",
       "      <td>(disperse, 0.1841)</td>\n",
       "      <td>(is, 0.1251)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(executioners, 0.1521)</td>\n",
       "      <td>(booted, 0.1673)</td>\n",
       "      <td>(prescription, 0.1175)</td>\n",
       "      <td>(interrupt, 0.25)</td>\n",
       "      <td>(thwarted, 0.1778)</td>\n",
       "      <td>(when, 0.1185)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(spit, 0.1503)</td>\n",
       "      <td>(kinsman, 0.1543)</td>\n",
       "      <td>(itches, 0.1173)</td>\n",
       "      <td>(unfit, 0.2277)</td>\n",
       "      <td>(angelical, 0.1754)</td>\n",
       "      <td>(she, 0.1136)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(demurely, 0.1469)</td>\n",
       "      <td>(tybalt, 0.1538)</td>\n",
       "      <td>(commended, 0.1166)</td>\n",
       "      <td>(unseemly, 0.2229)</td>\n",
       "      <td>(diverted, 0.1718)</td>\n",
       "      <td>(him, 0.1105)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(stabbed, 0.1466)</td>\n",
       "      <td>(slew, 0.1457)</td>\n",
       "      <td>(detestable, 0.1144)</td>\n",
       "      <td>(hunting, 0.2194)</td>\n",
       "      <td>(cools, 0.1652)</td>\n",
       "      <td>(me, 0.1105)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(rosencrantz, 0.1447)</td>\n",
       "      <td>(pined, 0.145)</td>\n",
       "      <td>(usurped, 0.114)</td>\n",
       "      <td>(conspires, 0.2166)</td>\n",
       "      <td>(resolutely, 0.1626)</td>\n",
       "      <td>(his, 0.1099)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(behove, 0.1437)</td>\n",
       "      <td>(friar, 0.1343)</td>\n",
       "      <td>(maculate, 0.1124)</td>\n",
       "      <td>(brine, 0.2037)</td>\n",
       "      <td>(obscene, 0.1574)</td>\n",
       "      <td>(himself, 0.1022)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      juliet               romeo                   royal  \\\n",
       "rank                                                                       \n",
       "1          (capulet, 0.1819)  (mercutio, 0.2296)  (encountering, 0.1827)   \n",
       "2           (tybalt, 0.1721)      (hist, 0.2165)       (carters, 0.1406)   \n",
       "3         (katarina, 0.1595)       (bon, 0.1892)    (dismantled, 0.1226)   \n",
       "4            (paris, 0.1534)      (jour, 0.1836)         (peril, 0.1184)   \n",
       "5     (executioners, 0.1521)    (booted, 0.1673)  (prescription, 0.1175)   \n",
       "6             (spit, 0.1503)   (kinsman, 0.1543)        (itches, 0.1173)   \n",
       "7         (demurely, 0.1469)    (tybalt, 0.1538)     (commended, 0.1166)   \n",
       "8          (stabbed, 0.1466)      (slew, 0.1457)    (detestable, 0.1144)   \n",
       "9      (rosencrantz, 0.1447)      (pined, 0.145)        (usurped, 0.114)   \n",
       "10          (behove, 0.1437)     (friar, 0.1343)      (maculate, 0.1124)   \n",
       "\n",
       "                       evil                wicked                 he  \n",
       "rank                                                                  \n",
       "1     (discoveries, 0.3079)   (spectacle, 0.2403)     (hath, 0.1525)  \n",
       "2     (ministering, 0.2747)     (bombast, 0.2196)     (that, 0.1416)  \n",
       "3          (clerks, 0.2669)      (absurd, 0.1914)       (it, 0.1257)  \n",
       "4           (crawl, 0.2594)    (disperse, 0.1841)       (is, 0.1251)  \n",
       "5         (interrupt, 0.25)    (thwarted, 0.1778)     (when, 0.1185)  \n",
       "6           (unfit, 0.2277)   (angelical, 0.1754)      (she, 0.1136)  \n",
       "7        (unseemly, 0.2229)    (diverted, 0.1718)      (him, 0.1105)  \n",
       "8         (hunting, 0.2194)       (cools, 0.1652)       (me, 0.1105)  \n",
       "9       (conspires, 0.2166)  (resolutely, 0.1626)      (his, 0.1099)  \n",
       "10          (brine, 0.2037)     (obscene, 0.1574)  (himself, 0.1022)  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\n",
    "    '\\nThe 10 most similar words to \"%s\" using cosine-similarity on ppmi matrix are:'\n",
    "    % (words)\n",
    ")\n",
    "get_ranks(ppmi_matrix, words, vocab, vocab_to_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In my opinion, the positive point-wise mutual information weighting method results in the best matrix. While I previously stated I believed the term-context and term-document matrices to be somewhat equal in terms of their representations, I believe the PPMI weights allow the term-context matrix to prevail.\n",
    "\n",
    "Though all the similarity values are low, the top words chosen based on this metric make the most sense. The proper nouns \"juliet\" and \"romeo\" are compared to other characters of their respective sexes in addition to being similar to words which adequately would describe the character. The pronoun \"he\" which previously had no similar words according to the tf-idf matrix now is considered to be similar to other pronouns. Additionally, \"wicked\" and \"evil\" are finally compared to words which I would consider similar (\"evil\" to \"conspires\" and \"wicked\" to \"obscene\"); no other technique has found generally similar words. \n",
    "\n",
    "The only term I find that this matrix struggled to represent is \"royal\", which ironically is a word that the other methods did somewhat well on. It is likely due to the nature of the stories on which these representations come from given that royalty can often be depcited as \"detestable\" or be in \"peril\". I do find this somewhat amusing since it can give an idea of how royalty was depicted in these stories without having read most of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## SimLex999 Comparison (Extra Credit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the performance of each vector model, I will use a non-parametric approach to calculating the correlation between the human annotated labels and the cosine similarity scores produced by the models.\n",
    "\n",
    "The non-parametric statistic being calculated is Kendall's $\\tau$ correlation. As with many non-parametric approaches, this is a rank-based calculation which can measure the monoticity of the relationship between two variables.\n",
    "\n",
    "$$\n",
    "-1 \\leq \\tau \\leq 1\n",
    "$$\n",
    "\n",
    "Where $\\tau \\rightarrow -1$ indicates disagreement (negative trend) while $\\tau \\rightarrow 1$ indicates an agreement (positive trend) between the two variables. I will be conducting an upper-tail test since we expected there to be a positive correlation between the human annotations and the cosine similarity scores.\n",
    "\n",
    "\\begin{align*}\n",
    "    \\alpha &= 0.10 \\\\\n",
    "    H_0 &: \\tau = 0 \\\\\n",
    "    H_1 &: \\tau > 0\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word1</th>\n",
       "      <th>word2</th>\n",
       "      <th>POS</th>\n",
       "      <th>SimLex999</th>\n",
       "      <th>conc(w1)</th>\n",
       "      <th>conc(w2)</th>\n",
       "      <th>concQ</th>\n",
       "      <th>Assoc(USF)</th>\n",
       "      <th>SimAssoc333</th>\n",
       "      <th>SD(SimLex)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>old</td>\n",
       "      <td>new</td>\n",
       "      <td>A</td>\n",
       "      <td>1.58</td>\n",
       "      <td>2.72</td>\n",
       "      <td>2.81</td>\n",
       "      <td>2</td>\n",
       "      <td>7.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>smart</td>\n",
       "      <td>intelligent</td>\n",
       "      <td>A</td>\n",
       "      <td>9.20</td>\n",
       "      <td>1.75</td>\n",
       "      <td>2.46</td>\n",
       "      <td>1</td>\n",
       "      <td>7.11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hard</td>\n",
       "      <td>difficult</td>\n",
       "      <td>A</td>\n",
       "      <td>8.77</td>\n",
       "      <td>3.76</td>\n",
       "      <td>2.21</td>\n",
       "      <td>2</td>\n",
       "      <td>5.94</td>\n",
       "      <td>1</td>\n",
       "      <td>1.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy</td>\n",
       "      <td>cheerful</td>\n",
       "      <td>A</td>\n",
       "      <td>9.55</td>\n",
       "      <td>2.56</td>\n",
       "      <td>2.34</td>\n",
       "      <td>1</td>\n",
       "      <td>5.85</td>\n",
       "      <td>1</td>\n",
       "      <td>2.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hard</td>\n",
       "      <td>easy</td>\n",
       "      <td>A</td>\n",
       "      <td>0.95</td>\n",
       "      <td>3.76</td>\n",
       "      <td>2.07</td>\n",
       "      <td>2</td>\n",
       "      <td>5.82</td>\n",
       "      <td>1</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word1        word2 POS  SimLex999  conc(w1)  conc(w2)  concQ  Assoc(USF)  \\\n",
       "0    old          new   A       1.58      2.72      2.81      2        7.25   \n",
       "1  smart  intelligent   A       9.20      1.75      2.46      1        7.11   \n",
       "2   hard    difficult   A       8.77      3.76      2.21      2        5.94   \n",
       "3  happy     cheerful   A       9.55      2.56      2.34      1        5.85   \n",
       "4   hard         easy   A       0.95      3.76      2.07      2        5.82   \n",
       "\n",
       "   SimAssoc333  SD(SimLex)  \n",
       "0            1        0.41  \n",
       "1            1        0.67  \n",
       "2            1        1.19  \n",
       "3            1        2.18  \n",
       "4            1        0.93  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simlex = pd.read_csv('./SimLex-999/SimLex-999.txt', sep = '\\t')\n",
    "simlex.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are primarily interested in the SimLex999 column which are the human annotated scores on the scale from [0,10]. Since this is a non-paremtric approach, there are no assumptions regarding the variance or expected values of the variables. Hence, the variables do not need to be standardized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simlex.shape = (999, 10)\n"
     ]
    }
   ],
   "source": [
    "print(f\"{simlex.shape = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 999 annotated words. Some of these words will not be in our vocabularly since our documents are primarily in old English, and I used a subset of them due to memory issues. If a word is not in the vocabulary, I will simply discard it as there is not a good way to approximate the similarity whilst retaining an accurate statistic of the correlation between the vector models and human annotators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sims = defaultdict(list)\n",
    "missed = []\n",
    "\n",
    "for row in range(simlex.shape[0]):\n",
    "    word1 = simlex['word1'][row]\n",
    "    word2 = simlex['word2'][row]\n",
    "    if (word1 not in vocab) or (word2 not in vocab):\n",
    "        missed.append((word1,word2))\n",
    "        continue\n",
    "\n",
    "    w1i = vocab_to_index[word1]\n",
    "    w2i = vocab_to_index[word2]\n",
    "\n",
    "    sims['words'].append((word1,word2))\n",
    "    sims['Term-Document'].append(compute_cosine_similarity(td_matrix[w1i,:],td_matrix[w2i,:]))\n",
    "    sims['Term-Context'].append(compute_cosine_similarity(tc_matrix[w1i,:],tc_matrix[w2i,:]))\n",
    "    sims['TF-IDF'].append(compute_cosine_similarity(tf_idf_matrix[w1i,:],tf_idf_matrix[w2i,:]))\n",
    "    sims['PPMI'].append(compute_cosine_similarity(ppmi_matrix[w1i,:],ppmi_matrix[w2i,:]))\n",
    "    sims['simlex'].append(simlex['SimLex999'][row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(missed) = 428\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(missed) = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There were 428 words not included in our vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kendall's Tau Coef. between Cosine Similarity with Term-Document and SimLex999 Human Annotations = -0.101397\n",
      "p-value = 0.999852\n",
      "\n",
      "Kendall's Tau Coef. between Cosine Similarity with Term-Context and SimLex999 Human Annotations = -0.078001\n",
      "p-value = 0.997301\n",
      "\n",
      "Kendall's Tau Coef. between Cosine Similarity with TF-IDF and SimLex999 Human Annotations = -0.030076\n",
      "p-value = 0.872027\n",
      "\n",
      "Kendall's Tau Coef. between Cosine Similarity with PPMI and SimLex999 Human Annotations = -0.023944\n",
      "p-value = 0.803487\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k,v in sims.items():\n",
    "    if k in ['words', 'simlex']: continue\n",
    "\n",
    "    kt = kendalltau(v, sims['simlex'], alternative='greater', variant = 'c')\n",
    "    print(f\"Kendall's Tau Coef. between Cosine Similarity with {k} and SimLex999 Human Annotations = {round(kt.statistic,6)}\")\n",
    "    print(f\"p-value = {round(kt.pvalue,6)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a reminder, the this is an upper-tailed test at $\\alpha = 0.10$ significance level. We can clearly see that none of the vector models come close to producing significant evidence that $\\tau \\neq 0$. Thus, none of the models demonstrate an agreement with the human annotators.\n",
    "\n",
    "The best model according to the $p$-value is the PPMI matrix, which I previously made a claim for being the best vector representation. Again, these representations were built from 12 documents, so if all 36 documents were used the conclusion could be drastically different from what was seen here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
